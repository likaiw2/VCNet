{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "read file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "    \n",
    "raw_data = np.fromfile(r\"C:\\Files\\Research\\dataSet0\\norm_ct.001.raw\", dtype=np.float32).reshape((160,224,168))\n",
    "print(raw_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test generate mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "raw_data.shape: (128, 128, 128)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tools\n",
    "\n",
    "# raw_data = np.fromfile(r\"C:\\Files\\Research\\dataSet0\\norm_ct.001.raw\", dtype=np.float32).reshape((160,224,168))\n",
    "raw_data = np.fromfile(r\"C:\\Files\\Research\\dataSet2\\original_volume_001.raw\", dtype=np.float32).reshape((128,128,128))\n",
    "print(\"raw_data.shape:\",raw_data.shape)\n",
    "\n",
    "mask_volume,mask = tools.generate_mask(raw_data.shape,7)\n",
    "\n",
    "new_data = raw_data * (1-mask_volume)\n",
    "new_data.astype('float32').tofile(r\"C:\\Files\\Research\\dataSet2\\atest001.raw\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "volume crop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# import tools\n",
    "\n",
    "# def crop_raw(origin_pos,new_pos,size=(128,128,128)):\n",
    "origin_pos = \"/Users/wanglikai/Codes/Volume_Complete/dataSet0/norm_mr.001.raw\"\n",
    "new_pos = \"/Users/wanglikai/Codes/test/norm_ct.001.raw\"\n",
    "size = (128,128,128)\n",
    "# read original volume data.\n",
    "old_data = np.fromfile(origin_pos, dtype=np.float32).reshape(160,224,168)\n",
    "assert (old_data.shape[0]>=size[0] and old_data.shape[1]>=size[1] and old_data.shape[2]>=size[2])\n",
    "n_range_r = old_data.shape[0]-size[0]\n",
    "y_range_l = old_data.shape[1]-size[1]\n",
    "z_range_l = int(old_data.shape[2]/2-size[2]/2)\n",
    "z_range_r = int(old_data.shape[2]/2+size[2]/2)\n",
    "new_data = old_data[:10,:10]\n",
    "# new_data = old_data[range(n_range_r)][range(y_range_l,size[1])][range(z_range_l,z_range_r)]\n",
    "new_data = old_data[old_data.shape[0]-size[0]:,old_data.shape[1]-size[1]-10:old_data.shape[1]-size[1]+118,int(old_data.shape[2]/2-size[2]/2):int(old_data.shape[2]/2+size[2]/2)]\n",
    "# 取n=[32:160],h=[86:214],w=[20:148]\n",
    "new_data.astype('float32').tofile(new_pos)\n",
    "\n",
    "\n",
    "# crop_raw(\"/Users/wanglikai/Codes/Volume_Complete/dataSet0/norm_ct.001.raw\",\"/Users/wanglikai/Codes/test/norm_ct.001.raw\",size=(128,128,128))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "size=(128,128,128)\n",
    "origin_pos = \"/Users/wanglikai/Codes/Volume_Complete/dataSet0/norm_ct.001.raw\"\n",
    "new_pos = \"/Users/wanglikai/Codes/test/norm_ct.001.raw\"\n",
    "# read original volume data.\n",
    "fileName = origin_pos\n",
    "old_data = np.fromfile(fileName, dtype=np.float32).reshape(160,224,168)\n",
    "assert (old_data.shape[0]>=size[0] and old_data.shape[1]>=size[1] and old_data.shape[2]>=size[2])\n",
    "\n",
    "# 取n=[32:160],h=[86:214],w=[20:148]最合适\n",
    "new_data = old_data[old_data.shape[0]-size[0]         :,\n",
    "                    old_data.shape[1]-size[1]-10      :old_data.shape[1]-size[1]+118,\n",
    "                    int(old_data.shape[2]/2-size[2]/2):int(old_data.shape[2]/2+size[2]/2)]\n",
    "\n",
    "new_data.astype('float32').tofile(new_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tools\n",
    "\n",
    "origin_pos = \"/Users/wanglikai/Codes/Volume_Complete/dataSet0/norm_ct.001.raw\"\n",
    "new_pos = \"/Users/wanglikai/Codes/test/norm_ct.001.raw\"\n",
    "tools.crop_raw_128(origin_pos=origin_pos,new_pos=new_pos)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Data:\n",
      "tensor([[3, 4],\n",
      "        [1, 2]])\n",
      "Batch Labels:\n",
      "tensor([1, 0])\n",
      "\n",
      "Batch Data:\n",
      "tensor([[7, 8],\n",
      "        [5, 6]])\n",
      "Batch Labels:\n",
      "tensor([1, 0])\n",
      "\n",
      "Batch Data:\n",
      "tensor([[ 9, 10]])\n",
      "Batch Labels:\n",
      "tensor([0])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "# 假设你有一些数据\n",
    "data = torch.tensor([[1, 2], [3, 4], [5, 6], [7, 8], [9, 10]])\n",
    "\n",
    "# 假设你有一些标签\n",
    "labels = torch.tensor([0, 1, 0, 1, 0])\n",
    "\n",
    "# 创建一个 TensorDataset 对象，将数据和标签组合起来\n",
    "dataset = TensorDataset(data, labels)\n",
    "\n",
    "# 使用 DataLoader 加载数据集，并设置 batch size 为 2\n",
    "dataloader = DataLoader(dataset, batch_size=2, shuffle=True)\n",
    "\n",
    "# 迭代 DataLoader 并获取每个批次的数据\n",
    "for batch_data, batch_labels in dataloader:\n",
    "    print(\"Batch Data:\")\n",
    "    print(batch_data)\n",
    "    print(\"Batch Labels:\")\n",
    "    print(batch_labels)\n",
    "    print()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
